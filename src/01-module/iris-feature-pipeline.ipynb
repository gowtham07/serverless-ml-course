{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2kLrOh-bpGy"
      },
      "source": [
        "# Iris Flower - Feature Pipeline\n",
        "\n",
        "In this notebook we will, \n",
        "\n",
        "1. Run in either \"Backfill\" or \"Normal\" operation. \n",
        "2. IF *BACKFILL==True*, we will load our DataFrame with data from the iris.csv file \n",
        "\n",
        "   ELSE *BACKFILL==False*, we will load our DataFrame with one synthetic Iris Flower sample \n",
        "3. Write our DataFrame to a Feature Group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NDBJE6n2Gx4",
        "outputId": "cb90612d-45ba-4d2c-b39e-d3d790b17f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 120 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 22.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 843 kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 35.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 950 kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 38.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 40.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 22.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 46.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 45.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 500 kB 38.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 37.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 38.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s \n",
            "\u001b[?25h  Building wheel for hopsworks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hsfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hsml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyhopshive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for twofish (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U hopsworks --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiT92BPa2Gx5"
      },
      "source": [
        "Set **BACKFILL=True** if you want to create features from the iris.csv file containing historical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLwUonc02Gx5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import hopsworks\n",
        "\n",
        "BACKFILL=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0flpWDO2Gx6"
      },
      "source": [
        "### Synthetic Data Functions\n",
        "\n",
        "These synthetic data functions can be used to create a DataFrame containing a single Iris Flower sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRmFM7vcbpHA"
      },
      "outputs": [],
      "source": [
        "def generate_flower(name, sepal_len_max, sepal_len_min, sepal_width_max, sepal_width_min, \n",
        "                    petal_len_max, petal_len_min, petal_width_max, petal_width_min):\n",
        "    \"\"\"\n",
        "    Returns a single iris flower as a single row in a DataFrame\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({ \"sepal_length\": [random.uniform(sepal_len_max, sepal_len_min)],\n",
        "                       \"sepal_width\": [random.uniform(sepal_width_max, sepal_width_min)],\n",
        "                       \"petal_length\": [random.uniform(petal_len_max, petal_len_min)],\n",
        "                       \"petal_width\": [random.uniform(petal_width_max, petal_width_min)]\n",
        "                      })\n",
        "    df['variety'] = name\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_random_iris_flower():\n",
        "    \"\"\"\n",
        "    Returns a DataFrame containing one random iris flower\n",
        "    \"\"\"\n",
        "    virginica_df = generate_flower(\"Virginica\", 8, 5.5, 3.8, 2.2, 7, 4.5, 2.5, 1.4)\n",
        "    versicolor_df = generate_flower(\"Versicolor\", 7.5, 4.5, 3.5, 2.1, 3.1, 5.5, 1.8, 1.0)\n",
        "    setosa_df =  generate_flower(\"Setosa\", 6, 4.5, 4.5, 2.3, 1.2, 2, 0.7, 0.3)\n",
        "\n",
        "    # randomly pick one of these 3 and write it to the featurestore\n",
        "    pick_random = random.uniform(0,3)\n",
        "    if pick_random >= 2:\n",
        "        iris_df = virginica_df\n",
        "    elif pick_random >= 1:\n",
        "        iris_df = versicolor_df\n",
        "    else:\n",
        "        iris_df = setosa_df\n",
        "\n",
        "    return iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpEGE5vp2Gx6"
      },
      "source": [
        "## Backfill or create new synthetic input data\n",
        "\n",
        "You can run this pipeline in either *backfill* or *synthetic-data* mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z3PZd7Q2Gx7"
      },
      "outputs": [],
      "source": [
        "\n",
        "if BACKFILL == True:\n",
        "    iris_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/iris.csv\")\n",
        "else:\n",
        "    iris_df = get_random_iris_flower()\n",
        "    \n",
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f71W8g_2Gx7"
      },
      "source": [
        "## Authenticate with Hopsworks using your API Key\n",
        "\n",
        "Hopsworks will prompt you to paste in your API key and provide you with a link to find your API key if you have not stored it securely already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpqxpDF92Gx7"
      },
      "outputs": [],
      "source": [
        "project = hopsworks.login()\n",
        "fs = project.get_feature_store()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOVznt-b2Gx8"
      },
      "source": [
        "## Create and write to a feature group - primary keys\n",
        "\n",
        "To prevent duplicate entries, Hopsworks requires that each DataFame has a *primary_key*. \n",
        "A *primary_key* is one or more columns that uniquely identify the row. Here, we assume\n",
        "that each Iris flower has a unique combination of (\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\")\n",
        "feature values. If you randomly generate a sample that already exists in the feature group, the insert operation will fail.\n",
        "\n",
        "The *feature group* will create its online schema using the schema of the Pandas DataFame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZPBQmQS2Gx8"
      },
      "outputs": [],
      "source": [
        "iris_fg = fs.get_or_create_feature_group(name=\"iris\",\n",
        "                                  version=1,\n",
        "                                  primary_key=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],\n",
        "                                  description=\"Iris flower dataset\"\n",
        "                                 )\n",
        "iris_fg.insert(iris_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv_VqeAi2Gx8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}